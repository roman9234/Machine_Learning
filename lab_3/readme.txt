3 лаба

Данные: https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments
Токенизатор: https://huggingface.co/ai-forever/ruBert-base

Задача написать RNN/GRU/LSTM (любую из) модель которая будет способна классифицировать текст на токсичный или не токсичный.
Датасет можно выбрать любой, но если лень искать то можете взять этот.
Советую аккуратно выбирать размеры модели так как у RNN моделей большие проблемы со скоростью обучения.

В качестве токенизатора можно взять любой токенизатор с hf
либо написать свой эмбеддинг слой который будет превращать именно слова в эмбеддинги, тут по желанию.

В качестве лосса это BCE. В качестве оптимизатор Adam/AdamW, lr=3e-4.

Но если захотите что другое то можно другое. Loss можете взвесить так как явный дисбаланс классов.
По метрикам считайте accuracy, f1, roc-auc, pr-auc. Не забудьте проводить расчеты на cuda.

Также советую подсчитать различные статистики по датасету и поставить всякие ограничения для ускорения обучения модели,
по типу ограничение на длину последовательности токенов.



Для самых крутых, можете засемплить распределение на обученой модели и исходное и посчитать forward KL
и убедиться что BCE оптимизирует MLE и из этого выходит что и KL оптимизируется


Также жду фидбек по сложности задания




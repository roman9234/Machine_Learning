Типы задач:

-регрессия = предсказание числа
-классификация


N-layer perceptron

На вход подаётся вектор x
Умножаем вектор на веса w

Есть 3 вида слоёв:
- входные
- скрытые
- выходные


Уравнение, которое описывает связь между двумя слоями:

a1 = σ ( W*a0 + b)

W - Матрица весов. Каждый нейрон 1 слоя связан со всеми нейронами 2 слоя.
a0 - Значение нейронов 1 слоя
a1 - Значение нейронов 2 слоя
b - сдвиг (Bias)

σ - сигмоида (функция активации), применяется к каждому члену вектора. При больших значениях функции стремиться к единице, при отрицательных - к 0
Формула сигмоиды F(x):
F(x) = 1/(1+e^(-x))

---- градиентный спуск ----

У выходного слоя необученной нейросети есть некоторые значения.
Мы высчитываем уровень ошибки нейросети, сравнивая нужные и реальные значения выходного слоя.

MAE = ( |y1-y1^| + |y2-y2^| ) / 2
Можно также возводить ошибку в квадрат, тогда это будет квадрат ошибки
MSE = ( (y1-y1^)^2 + (y2-y2^)^2 ) / 2
Есть также менее популярные - RMSE, MAP

Ошибка считается как среднее от множества экспериментов в выборке

Теперь представим нейросеть как функцию:
C(w) = E
w - все параметры нейросети (матрица весов, смещения)
E - уровень ошибки

Процесс обучения сводится к поиску локального или глобального минимума этой функции.
То есть нужно подобрать x так, чтобы E была минимальной.


----
Минимум можно найти используя Градиент
Отрицательный градиент указывает нам направление, в котором функция убывает
Длина вектора градиента указывет, насколько крут спуск

----
Как посчитать это вектор?

Представим все веса и смещения нашей сети как огромный вектор W
Отрицательный градиент функции ошибки - это просто вектор.

Некое направление внутри огромного пространства параметров,
которое говорит какой сдвиг всех этих чисел вызовет самое быстрое убывание функции ошибки

Функция ошибки вклюает себя среднее от всех примеров. Минимизируя её, мы улучшаем резуультат на всех примерах


----
Алгоритм вычисления градиента - Алгоритм обратного распространения ошибки
Процесс сдвигания значения на отрицательный градиент - и есть градиентный спуск. Это способ приблизиться к локальному минимуму функции ошибки


===Как работает алгоритм обратного распространения ошибки?

У нас есть выходной слой. Есть разница реальных и ожидаемых значений
Некоторые значения нужно повысить, другие понизить

Пусть нам надо повысить значение одного из 10 выходных нейронов, а остальные понизить

Активация - это взвешенная сумма активации предыдущего слоя + смещение, которые было подключено к функции сглаживания
Есть три разных метода, объединение которых помогает увеличить искомое значение
- увеличить смещение
- увеличить веса
связи с самыми активными нейронами предыдущего слоя имеют больший эффект
- изменить активации предыдущего слоя
Если всё что имеет положительный вес w становится ярче, и всё с отрицательным w тусклее, нужный нам нейрон становится более активным
Итого у нас получается некоторая длина векторов необходимых изменений предыдущих нейронов

Для каждого выходого нейрона изменения предыдущего слоя свои, пропорциональны их связям с нейронами предыдущего слоя
Мы складываем все вычислинные изменения нейронов первого слоя
В итоге мы получаем список изменений, которые должны произойти с предыдущим слоем

Затем мы повторяем ту же последовательность действий для нейронов ещё более глубокого слоя

После завершения цикла, необходимо повторять все эти шаги для каждого элемента обучающего набора данных
Настоящий градтиент функции оценки требует всех элементов обучающего набора
Но для производительности, после каждой эпохи элементы датасета перемешиваются, и распределяются по батчам фиксированного размера

===Эта техника называется стахастическим градиентным спуском



---- Функции активации ----
Сигмоида используется на выходгных слоях.
У сигмоиды простая производная, равна = σ * (1-σ)
Максимальное значение производной - 0.25


Есть ещё РЕЛУ:
y = max(0, x)

Есть много других функций, но они все сожи с РЕЛУ






----
Multiple Perceptron - простая полносвязаня сеть. Все нейроны связаны с каждым нейроном следующего уровня
Сеть с такой простой структурой может просто запомнить данные и выдавать высокую точность, без понимания струуктуры анализируемых объектов
полносвязный слой / Dense слой / Linear слой
В полносвязной сети проход данных это:
Умножение входных данных на матрицу весов



---- Нужны функции активации, которые линейность убирают






---- Рилу ----


Все они используются в задачах регрессии


Логиты - выходные данные. Принимают любые значения

SoftMax ограничивает их
SoftMax - сумма вероятностей равна 1

Далее еспользуется лагорифм так как сумму лагорифмов намного проще дифференцировать


Из этого возникает кросс-энтропия. Когда мы считаем не по вероятности,
а запихиваем в лагорифм то что нам нужно со знаком минус
Кросс-энтропия лосс используется при классификации

Уравнение кросс-энтропии лосс из природы вышла

Кросс энтрапилосс



Градиент - производная для случаев




Альфа - Learning Rate. Почти всегда меньше 0

В оптимизаторе атом должен быть равен 3e-4

В больших моделях 5e-5

Алгоритмов для генерации весов есть множество

Теперь когда посчитали градиент

Нужно уменьшить лосс
Как применить изменения? - Граф измерений

Back propogation - прогоняем граф в обратную сторону посчитав ошибку и градиент от этой ошибки

chain rule

анти градиент смотрит в сторону уменьшения функции ошибки

Мыы строим граф вычислений так как каждую операцию монжо сделать производную

Как применять градиент к весам - разные подходы. Называются оптимизаторыы

Есть ещ спуск не по одному элементу а по батчам


Существуют разные подходы к уменьшению Learning Rate
Так как чем ближе мы к минимальному лоссу тем меньше шаги



Как понять что модель переобучена? Посмотреть на график эпох
Эпоха - это когда полностью прошлись по датасету
Всегда есть 3 выборки - train validate test
train - учимся
validate - после каждой эпохи ссмотрим как модель ошибается. Валидацию модель не выучивает

После каждой эпохи смотрим уровень ошибки на валидации

overfitting - одновременное падение ошибки на train и рост ошибки на валидации



Стэйминг
Лигмантизация











